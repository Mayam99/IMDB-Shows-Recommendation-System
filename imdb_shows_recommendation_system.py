# -*- coding: utf-8 -*-
"""IMDB -Shows-Recommendation-System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tfUswlOqXh_ZGfo_GANAkRR_cWU9W_e_

##Introduction to the IMDB Top 250 Shows Dataset
###The IMDB Top 250 Shows dataset is a comprehensive collection of information about the top-rated television shows as ranked by the Internet Movie Database (IMDB). This dataset is widely used for analysis and development of recommendation systems, providing insights into the attributes that make these shows popular among viewers.

###This dataset is having the data of the top 250 Shows as per their IMDB rating listed on the official website of IMDB

###Features

* rank - Show Rank as per IMDB rating
* show_id - Show ID
* title - Name of the Show
* year - Year of Show release
* link - URL for the Show
* imdb_votes - Number of people who voted for the IMDB rating
* imdb_rating - Rating of the Show
* certificate - Show Certification
* duration - Duration of the Show
* genre - Genre of the Show
* cast_id - ID of the cast member who have worked on the Show
* cast_name - Name of the cast member who have worked on the Show
* director_id - ID of the director who have directed the Show
* director_name - Name of the director who have directed the Show
* writer_id - ID of the writer who have wrote script for the Show
* writer_name - Name of the writer who have wrote script for the Show
* storyline - Storyline of the Show
* user_id - ID of the user who wrote review for the Show
* user_name - Name of the user who wrote review for the Show
* review_id - ID of the user review
* review_title - Short review
* review_content - Long review


##Source

https://www.kaggle.com/datasets/karkavelrajaj/imdb-top-250-shows/data

##Importing Necessary Libraries
"""

import pandas as pd #Pandas is a powerful library for data manipulation and analysis.

df = pd.read_csv('shows.csv') #Loading the dataset.

"""###We will now read the data from a CSV file into a Pandas DataFrame Let us have a look at how our dataset looks like using df.head()"""

df.head() #Displays the first 5 rows of the dataset.

"""##Exploring the Data:
###Understanding the dataset by exploring its structure and contents.
"""

df.columns # Displays the names of the columns

df.shape # Displays the total count of the Rows and Columns respectively.

df.info() #Displays the total count of values present in the particular column along with the null count and data type.

"""##Data Cleaning:
###Checking for missing values, duplicates, or any inconsistencies and clean the data accordingly.
"""

df.isnull().sum()

"""As we can check there is only 4 null value in the certificate column and duration has 1 null value. As the count of the null value is much less, we can drop the null value as it will not affect the the out come as what we want to predict."""

df = df.dropna() #Dropping the null values in the dataset.

df.isnull().sum() #Displays the total count of the null values in the particular columns.

"""Now there is no null value in the dataset."""

df.drop_duplicates(inplace=True) #Dropping the duplicate values in the dataset.

import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder

"""#Content-Based Filtering:

Normalizing the ratings using StandardScaler ensures that the ratings are on a comparable scale, leading to improved performance and stability of the recommendation system
"""

# Normalize ratings
scaler = StandardScaler()
df['normalized_rating'] = scaler.fit_transform(df[['imbd_rating']])

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""###The code snippet tfidf = TfidfVectorizer(stop_words='english'); tfidf_matrix = tfidf.fit_transform(df['genre']) is part of the process to convert text data into numerical features that can be used in machine learning models.
###TF-IDF Vectorization
###TF-IDF stands for Term Frequency-Inverse Document Frequency. It is a statistical measure used to evaluate the importance of a word in a document relative to a collection of documents (or corpus). The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus.
"""

# Feature extraction
tfidf = TfidfVectorizer(stop_words='english') #This creates an instance of TfidfVectorizer that will ignore common English stop words.
tfidf_matrix = tfidf.fit_transform(df['genre'])

"""###fit_transform(df['genre']) does two things:
###Fit: It learns the vocabulary from the genre column, determining the term frequency and document frequency for each term in the genres.
###Transform: It then converts each genre string into a TF-IDF vector. Each row in the resulting tfidf_matrix corresponds to a show, and each column corresponds to a term from the genre data, with the cell values representing the TF-IDF scores.

"""

# Calculate similarity
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

"""###The cosine_similarity function takes two matrices as input and computes the cosine similarity between the rows of these matrices.
###By passing tfidf_matrix twice, you compute the similarity between every pair of shows in the dataset.
"""

# Function to get recommendations
def get_recommendations(title, cosine_sim=cosine_sim): #title: The title of the show for which we want to get recommendations. cosine_sim: The precomputed cosine similarity matrix (default value is cosine_sim).
    idx = df[df['title'] == title].index[0] #This line finds the index of the show with the given title in the DataFrame df.
    sim_scores = list(enumerate(cosine_sim[idx])) #This line retrieves the cosine similarity scores for the show at index idx from the cosine_sim matrix.
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True) #This line sorts the list of similarity scores in descending order based on the similarity score.
    sim_scores = sim_scores[1:11] #This line selects the top 10 most similar shows, excluding the first one
    show_indices = [i[0] for i in sim_scores] #This line extracts the indices of the top 10 similar shows from the sim_scores list.
    return df['title'].iloc[show_indices] #This line returns the titles of the shows corresponding to the extracted indices.

recommendations = get_recommendations('Planet Earth') #As we input the name of the show, we get the reccomendations.
recommendations

recommendations = get_recommendations('Chernobyl') #As we input the name of the movie, we get the reccomendations.
recommendations